# -------------------------------------------------------
# SISTEMA DE RECOMENDACI√ìN BASADO EN CONTENIDO (TF-IDF + LSA)
# CON PERSISTENCIA DE MODELO Y DETECCI√ìN AUTOM√ÅTICA DE NUEVAS REVISTAS
# Autor: Tadeo Manuel Portillo Guzm√°n
# Proyecto: Plataforma "Destinos Turismo"
# -------------------------------------------------------

import os
import pandas as pd
import joblib
from sqlalchemy import create_engine
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import TruncatedSVD
from sklearn.metrics.pairwise import cosine_similarity
import nltk
from nltk.corpus import stopwords

# ------------------------------------------
# 1Ô∏è‚É£ CONFIGURACI√ìN DE CONEXI√ìN A LA BD
# ------------------------------------------
DB_USER = "root"  # <-- coloca tu usuario MySQL
DB_PASS = "root"  # <-- coloca tu contrase√±a
DB_HOST = "localhost"
DB_NAME = "impplacc_destinos"

# Crear conexi√≥n SQLAlchemy
engine = create_engine(f"mysql+pymysql://{DB_USER}:{DB_PASS}@{DB_HOST}/{DB_NAME}")

# Carpeta donde se guardar√°n los modelos
MODEL_DIR = "models"
os.makedirs(MODEL_DIR, exist_ok=True)

# Rutas de los archivos de modelo
VECTORIZER_PATH = os.path.join(MODEL_DIR, "vectorizer.joblib")
LSA_PATH = os.path.join(MODEL_DIR, "lsa_model.joblib")
DF_PATH = os.path.join(MODEL_DIR, "revistas_df.joblib")


# ------------------------------------------
# 2Ô∏è‚É£ FUNCI√ìN DE ENTRENAMIENTO
# ------------------------------------------
def entrenar_modelo():
    print("\nüß† Entrenando modelo TF-IDF + LSA...")

    query = """
    SELECT 
        id,
        title,
        COALESCE(description, '') AS description,
        COALESCE(keywords, '') AS keywords,
        COALESCE(topics, '') AS topics,
        COALESCE(region, '') AS region
    FROM magazine;
    """

    df = pd.read_sql(query, engine).fillna("")

    # Combinar campos sem√°nticos en un solo texto
    df["texto_final"] = (
        df["title"]
        + " "
        + df["description"]
        + " "
        + df["keywords"]
        + " "
        + df["topics"]
        + " "
        + df["region"]
    )

    # Descargar stopwords en espa√±ol
    nltk.download("stopwords", quiet=True)
    spanish_stopwords = stopwords.words("spanish")

    # TF-IDF
    vectorizer = TfidfVectorizer(stop_words=spanish_stopwords, max_features=5000)
    tfidf_matrix = vectorizer.fit_transform(df["texto_final"])

    # LSA (reducci√≥n de dimensionalidad)
    lsa = TruncatedSVD(n_components=100, random_state=42)
    lsa_matrix = lsa.fit_transform(tfidf_matrix)

    # Guardar los artefactos
    joblib.dump(vectorizer, VECTORIZER_PATH)
    joblib.dump(lsa, LSA_PATH)
    joblib.dump(df, DF_PATH)

    print("‚úÖ Modelos entrenados y guardados correctamente.\n")

    return df, vectorizer, lsa, lsa_matrix


# ------------------------------------------
# 3Ô∏è‚É£ DETECCI√ìN AUTOM√ÅTICA DE NUEVOS REGISTROS
# ------------------------------------------
def necesita_reentrenamiento():
    """
    Retorna True si hay cambios en la cantidad de revistas
    o si no existen los modelos guardados.
    """
    # Si no existen archivos, entrenar desde cero
    if not (
        os.path.exists(VECTORIZER_PATH)
        and os.path.exists(LSA_PATH)
        and os.path.exists(DF_PATH)
    ):
        print("‚öôÔ∏è Modelos no encontrados. Se entrenar√° por primera vez.")
        return True

    # Cargar DataFrame guardado del modelo anterior
    df_guardado = joblib.load(DF_PATH)
    num_guardado = len(df_guardado)

    # Consultar cantidad actual de revistas en BD
    query = "SELECT COUNT(*) AS total FROM magazine;"
    total_actual = pd.read_sql(query, engine)["total"][0]

    # Comparar
    if total_actual != num_guardado:
        print(
            f"üìà Cambios detectados en la tabla magazine "
            f"({total_actual} actuales vs {num_guardado} previos)."
        )
        return True

    print("‚úÖ No se detectaron cambios en la tabla magazine.")
    return False


# ------------------------------------------
# 4Ô∏è‚É£ CARGA O REENTRENAMIENTO AUTOM√ÅTICO
# ------------------------------------------
if necesita_reentrenamiento():
    df, vectorizer, lsa, lsa_matrix = entrenar_modelo()
else:
    print("üíæ Cargando modelos existentes...\n")
    vectorizer = joblib.load(VECTORIZER_PATH)
    lsa = joblib.load(LSA_PATH)
    df = joblib.load(DF_PATH)

    nltk.download("stopwords", quiet=True)
    spanish_stopwords = stopwords.words("spanish")
    tfidf_matrix = vectorizer.transform(df["texto_final"])
    lsa_matrix = lsa.transform(tfidf_matrix)
    print("‚úÖ Modelos cargados correctamente.\n")

# ------------------------------------------
# 5Ô∏è‚É£ MATRIZ DE SIMILITUD
# ------------------------------------------
similaridades = cosine_similarity(lsa_matrix)


# ------------------------------------------
# 6Ô∏è‚É£ FUNCI√ìN DE RECOMENDACI√ìN
# ------------------------------------------
def recomendar_revistas(id_revista, top_k=5):
    """
    Retorna las revistas m√°s similares a una revista dada.
    """
    if id_revista not in df["id"].values:
        print("‚ùå El ID de revista no existe en la base de datos.")
        return None

    idx = df.index[df["id"] == id_revista][0]
    sim_scores = list(enumerate(similaridades[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)

    # Excluir la revista original
    sim_scores = [s for s in sim_scores if s[0] != idx]
    top_similares = sim_scores[:top_k]

    recomendaciones = df.iloc[[i for i, _ in top_similares]][["id", "title", "region"]]
    recomendaciones["similaridad"] = [round(s, 3) for _, s in top_similares]

    return recomendaciones


# ------------------------------------------
# 7Ô∏è‚É£ EJEMPLO DE USO
# ------------------------------------------
if __name__ == "__main__":
    print(
        "üîç SISTEMA DE RECOMENDACI√ìN DE REVISTAS (con Joblib + detecci√≥n de nuevos registros)\n"
    )
    try:
        ejemplo_id = int(input("Ingrese el ID de la revista para recomendar: "))
        resultado = recomendar_revistas(ejemplo_id, top_k=5)

        if resultado is not None:
            print("\nüß≠ Revistas m√°s similares:\n")
            print(resultado.to_string(index=False))
    except Exception as e:
        print(f"\n‚ö†Ô∏è Error: {e}")
